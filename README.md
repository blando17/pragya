# pragya
Let‚Äôs walk through your code line by line and then give a summary at the end.

‚∏ª

üîß Imports

import cv2
import time
import mediapipe as mp
import pyttsx3
import random
import sys
import json
import webbrowser
import speech_recognition as sr
from datetime import datetime

These are the required libraries:
	‚Ä¢	cv2: for capturing and processing video (OpenCV).
	‚Ä¢	time: to handle delays and timestamps.
	‚Ä¢	mediapipe: to detect hand landmarks.
	‚Ä¢	pyttsx3: for text-to-speech.
	‚Ä¢	random: for random computer moves in Rock Paper Scissors.
	‚Ä¢	sys: to exit the program.
	‚Ä¢	json: to read a local knowledge base.
	‚Ä¢	webbrowser: to open websites via voice commands.
	‚Ä¢	speech_recognition: to capture and recognize voice.
	‚Ä¢	datetime: to fetch time/date/day info.

‚∏ª

Load Knowledge Base

with open("knowledge_base.json", "r") as f:
    knowledge = json.load(f)

Loads pre-defined question-answer pairs (like a mini chatbot knowledge set) from a local JSON file.

‚∏ª

 Engine Setup

recognizer = sr.Recognizer()
engine = pyttsx3.init()
engine.setProperty('rate', 180)

	‚Ä¢	recognizer: sets up voice input.
	‚Ä¢	engine: initializes text-to-speech.
	‚Ä¢	rate: controls speech speed.

‚∏ª

üó£ Speak Function

def speak(text):
    engine.say(text)
    engine.runAndWait()

Speaks any provided text using pyttsx3.

‚∏ª

 Gesture Detection (Rock Paper Scissors)‚úä‚úã‚úåÔ∏è

Detect Hand Gesture

def detect_gesture(hand_landmarks):
    ...

	‚Ä¢	Uses MediaPipe hand landmarks.
	‚Ä¢	Detects finger positions to classify gesture as:
	‚Ä¢	Rock: all fingers down
	‚Ä¢	Paper: all fingers up
	‚Ä¢	Scissors: index and middle up
	‚Ä¢	Returns "rock", "paper", "scissors" or "none"

Get Winner

def get_winner(user, comp):
    ...

Compares user and computer gestures to decide winner.

Play Game

def play_rps():
    ...

	1.	Uses webcam + MediaPipe to detect gestures.
	2.	Every 5 seconds, compares user‚Äôs gesture vs random computer move.
	3.	Speaks out result and keeps score.
	4.	Ends on pressing Q.

‚∏ª

 Command Processor

def processCommand(c):
    ...

Processes voice commands such as:
	‚Ä¢	Replies to known questions from JSON knowledge base.
	‚Ä¢	Opens websites like Google, YouTube, etc.
	‚Ä¢	Tries to play music from an external musiclibrary (optional).
	‚Ä¢	Stops the assistant.
	‚Ä¢	Tells time, date, day.
	‚Ä¢	Launches Rock Paper Scissors.
	‚Ä¢	Responds with fallback if command is unknown.

‚∏ª

 Main Loop

if __name__ == "__main__":
    ...

This is the core loop of the assistant:
	1.	Speaks ‚ÄúInitializing Praggya‚Äù.
	2.	Listens continuously using the microphone.
	3.	Activates when it hears ‚ÄúPragya‚Äù.
	4.	Then listens for a command and processes it.

‚∏ª

‚ö° Summary

This script is your all-in-one voice assistant + gesture game system. Here‚Äôs what it does:
	‚Ä¢	Listens for the wake word ‚ÄúPragya‚Äù.
	‚Ä¢	Replies to known Q&A from a local JSON knowledge base.
	‚Ä¢	Can open popular websites on command.
	‚Ä¢	Recognizes spoken commands like time/date or music.
	‚Ä¢	Launches a Rock Paper Scissors game using webcam + hand gestures (via MediaPipe).
	‚Ä¢	Provides spoken feedback via text-to-speech.

